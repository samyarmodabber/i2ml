---
title: "Chapter 04.04: Test Error"
weight: 4004
quizdown: true
---
While we can infer some information about the learning process from training errors (e.g., the state of iterative optimization), we are truly interested in generalization ability, and thus in the test error on previously unseen data. 

<!--more-->

### Lecture video

{{< video id="ikz87m84um8" >}}

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_i2ml/blob/master/slides-pdf/slides-evaluation-test.pdf" >}}

### Quiz

{{< quizdown >}}

---
shuffle_questions: false
---

## Which statements are true? 

- [x] Overfitting means that the model performs much better on the training data than on the test data.
- [ ] A good test performance is an indicator of overfitting.
- [ ] The linear model is known to overfit very fast.
- [x] Overfitting risk increases with model complexity.
- [x] Constraining the hypothesis space helps the learner to find a good hypothesis.
- [ ] Goodness-of-fit measures like $R^2$, likelihood, AIC, BIC and deviance are all based on the test error.

{{< /quizdown >}}
