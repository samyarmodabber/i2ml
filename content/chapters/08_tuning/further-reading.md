---
title: "Tuning: Further Reading"
weight: 8006
---

#### Literature

{{< pdfjs file="https://github.com/slds-lmu/i2ml/blob/hpo-link/content/appendix/references.pdf" >}}

#### Further Material

- Bischl, Bernd, et al. ["Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges."](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1484) Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery (2021): e1484.  
    This paper goes beyond grid search and random search and reviews important automatic hyperparameter optimization (HPO) methods, provides practical recommendations for conducting HPO, and discusses HPO algorithms, performance evaluation, combination with machine learning pipelines, runtime improvements, and parallelization.
