---
title: "Chapter 08.03: Basic Techniques"
weight: 8003
quizdown: true
---
In this section we familiarize ourselves with two simple but popular tuning strategies, namely grid search and random search, and discuss their advantages and disadvantages. 

<!--more-->

### Lecture video

{{< video id="A1cx4FkS0lw" >}}

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_i2ml/tree/master/slides-pdf/slides-tuning-basicalgos.pdf" >}}

### Quiz

{{< quizdown >}}

---
shuffle_questions: false
---

## Which statements are true? 

- [x] How well tuning works depends on the learner and the impact of the hyperparameters on that learner.
- [ ] Grid search often works better than random search.
- [x] Grid search scales exponentially with the dimension of the parameter space.
- [x] Grid search evaluates many points from the parameter space that aren't of interest.
- [x] Random search works often better due to its better exploration of the hyperparameter space.
- [ ] Random search scales very well with the dimension of the hyperparameter space. 
- [ ] Random search as well as grid search has the problem of discretization.

{{< /quizdown >}}